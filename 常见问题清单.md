

### 1、openFeign直连api，不经过nacos

```java
@FeignClient(value = "acc", url = "http://localhost:8092/acc")
public interface FeignAccountService {
    @PostMapping("/user/list")
    Result userList(@RequestBody UserListDTO userListDTO);
}
```

参考：[[FEIGN 直连API，FEIGN不使用EUREKA直接调用微服务](https://www.greenhtml.com/archives/feign-direct-api.html)](https://www.greenhtml.com/archives/feign-direct-api.html)

### 2、openFeign日志打印

feign提供了日志打印功能，可以通过配置来调整日志级别，从而了解Feign中HTTP请求的细节
日志级别有一下四个：
none：默认的，不显示任何日志
basic：仅记录请求方法，URL响应状态码，及执行时间
headers：除了basic中定义的信息之外还有请求和响应头信息
full：除了headers中定义的信息之外，还有请求和响应的正文及元数据
具体配置如下：
一、 新建配置类FeignConfig

```java
@Configuration
public class FeignConfig {
    @Bean
    Logger.Level feignLoggerLevel(){
        return Logger.Level.FULL;
    }
}
1234567
```

二、yml文件

```java
logging:
  level:
     #feogn日志以什么级别监视那个接口
     com.zhutianlu.springcloud.service.PaymentFeignService: debug
```

### 3 Feign Hystrix (HystrixCommonKey) 设置单独接口的超时时间和FallBack

如何配置好`Hystrix`和`Ribbon`的超时时间呢？
其实是有套路的。因为`Feign`的请求：其实是`Hystrix`+`Ribbon`。`Hystrix`在最外层，然后再到`Ribbon`，最后里面的是`http`请求。所以说。`Hystrix`的熔断时间必须大于`Ribbon`的 ( `ConnectTimeout` + `ReadTimeout` )。而如果`Ribbon`开启了重试机制，还需要乘以对应的重试次数，保证在`Ribbon`里的请求还没结束时，`Hystrix`的熔断时间不会超时。

**先说结论：HystrixCommonKey生成方法：类名#方法名(入参类型)**

```yaml
hystrix:
  threadpool:
    default:
      # 核心线程池大小  默认10
      coreSize: 20
      # 最大最大线程池大小
      maximumSize: 30
      # 此属性允许maximumSize的配置生效。 那么该值可以等于或高于coreSize。 设置coreSize <maximumSize会创建一个线程池，该线程池可以支持maximumSize并发，但在相对不活动期间将向系统返回线程。 （以keepAliveTimeInMinutes为准）
      allowMaximumSizeToDivergeFromCoreSize: true
      # 请求等待队列
      maxQueueSize: 10
      # 队列大小拒绝阀值 在还未超过请求等待队列时也会拒绝的大小
      queueSizeRejectionThreshold: 10
  command:
    LimitCheckApi#rcsLimitCheck(RpcRequest):  #default全局有效 默认值为 commonKey commonKey生成方法在 Feign.configKey(target.type(), method) 中
      fallback:
        enabled: true
      execution:
        timeout:
          #如果enabled设置为false，则请求超时交给ribbon控制,为true,则超时作为熔断根据
          enabled: true
        isolation:
          #隔离策略，有THREAD和SEMAPHORE
          #THREAD - 它在单独的线程上执行，并发请求受线程池中的线程数量的限制
          #SEMAPHORE - 它在调用线程上执行，并发请求受到信号量计数的限制
          #对比：https://www.cnblogs.com/java-synchronized/p/7927726.html
          thread:
            timeoutInMilliseconds: 800 #断路器超时时间，默认1000ms
    LimitCheckApi#testTimeOutFallBack(long):
      fallback:
        enabled: true
      execution:
        timeout:
            #如果enabled设置为false，则请求超时交给ribbon控制,为true,则超时作为熔断根据
            enabled: true
        isolation:
          #隔离策略，有THREAD和SEMAPHORE
          #THREAD - 它在单独的线程上执行，并发请求受线程池中的线程数量的限制
          #SEMAPHORE - 它在调用线程上执行，并发请求受到信号量计数的限制
          #对比：https://www.cnblogs.com/java-synchronized/p/7927726.html
          thread:
            timeoutInMilliseconds: 800 #断路器超时时间，默认1000ms
 
feign:
  hystrix:
    enabled: true
```

参考: 

[Hystrix针对某个方法单独设置超时时间](https://blog.csdn.net/jerry010101/article/details/90143919?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-2&spm=1001.2101.3001.4242)

[SpringCloud OpenFeign超时配置详解](https://blog.csdn.net/a1036645146/article/details/108297183)

### 4 mybatis-plus 自定义查询SQL

- 使用@select注解 + Wrapper 

```java
@Select("select * from `user` ${ew.customSqlSegment}")
List<User> selectAll(@Param(Constants.WRAPPER) Wrapper wrapper);
```

- 使用xml + Wrapper 

  ```java
  List<User> selectAll(@Param(Constants.WRAPPER) Wrapper wrapper);
  ```

  ```xml
  <select id="selectAll" resultType="com.zimug.example.model.User">
    select * from `user` ${ew.customSqlSegment}
  </select>
  ```

- 测试

  ```java
  @Test
  public void testCustomSQL2() {
    LambdaQueryWrapper<User> query = new LambdaQueryWrapper<>();
    query.eq(User::getName, "字母");
  
    List<User> list = userMapper.selectAll(query);
    list.forEach(System.out::println);
  }
  ```


### 5、arthas热部署

- 1 jad命令` 将需要更改的文件先进行反编译，保存下来 ，编译器修改。修改完以后需要将类重新加载到JVM

```java
$ jad --source--only com.example.demo.DemoApplication > /data/DemoApplication.java
```

- 2 `SC命令` “Search-Class” 的简写，查找当前类是哪个classLoader加载的

  ```bash
  [arthas@16340]$ sc -d *ApiInterceptor |grep classLoader
   classLoaderHash   18b4aac2		#类加载器  编号
  ```

- 3 MC (Memory Compiler/内存编译器)，编译`.java`文件生成`.class` 

  `MC命令` 用指定的classloader重新将类在内存中编译

  ```bash
  $ mc -c 18b4aac2 /data/DemoApplication.java -d /data 
  Memory compiler output:
  /data/com/example/demo/DemoApplication.class
  ```

- 4 redefine：加载外部的`.class`文件，redefine jvm已加载的类。

  ```bash
  $ redefine /data/com/example/demo/DemoApplication.class  
  redefine success, size: 1
  ```

  这样我们就用`arthas`现实了不停机、不发包替换了生产环境的Java代码

### 6.springboot打成jar包后无法解压

Springboot打出来的jar，用压缩工具解压报错。Why? 先说解决办法

#### 1、解决办法

> executable属性导致的，属性改成false后重新打包，就可以解压

```
<plugin>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-maven-plugin</artifactId>
    <configuration>
        <executable>true</executable>
    </configuration>
</plugin>
```

那么，executable设置成true作用是什么呢？为什么设置成true就无法解压呢？

#### 2、executable设置成true作用

一般情况下，我们运行jar的方式为：

> java -jar xxx.jar

但如果你想在unix/linux上，像执行某个sh/服务那样运行jar，就需要把你的app打包成executable的jar。

官方解释：

> In addition to running Spring Boot applications by using `java -jar`, it is also possible to make fully executable applications for Unix systems. A fully executable jar can be executed like any other executable binary or it can be [registered with `init.d` or `systemd`](https://docs.spring.io/spring-boot/docs/current/reference/html/deployment-install.html#deployment-service). This makes it very easy to install and manage Spring Boot applications in common production environments.

【A fully executable jar】就是通过前面提到的，打包时把executable设置为true。

#### 3、无法解压的原因分析

完全可执行 的 jar/war 在文件前面嵌入了个 额外的脚本，这就使得有些命令会执行失败，比如 jar -xf 等。

这就是为什么解压工具无法解压的原因。

所以，如果你的jar是通过【java -jar】执行、或 放在servlet容器中执行，那么建议将executable设置为false。

> Fully executable jars work by embedding an extra script at the front of the file. Currently, some tools do not accept this format, so you may not always be able to use this technique. For example, `jar -xf` may silently fail to extract a jar or war that has been made fully executable. It is recommended that you make your jar or war fully executable only if you intend to execute it directly, rather than running it with `java -jar` or deploying it to a servlet container.

#### 4、参考资料

https://docs.spring.io/spring-boot/docs/current/reference/html/deployment-install.html#deployment-service

### 7 logback 日志分隔

需求：异步输出日志，日志文件按照每天进行分隔。

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <contextName>logback</contextName>
    <!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义变量后，可以使“${}”来使用变量。 -->
    <property name="LOG_HOME" value="./logs" />
    <property name="FILE_NAME" value="api"/>

    <!--输出到控制台-->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息-->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>debug</level>
        </filter>
        <encoder>
            <Pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</Pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!--输出到文件-->
    <appender name="LOG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 正在记录的日志文件的路径及文件名 -->
        <file>${LOG_HOME}/${FILE_NAME}.log</file>
        <!--日志文件输出格式-->
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 日志记录器的滚动策略，按日期，按大小记录 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- 日志归档 -->
            <!-- #######################	重点这里有坑！！！ 用到了两次%d，第一个%d是为了获取[年月]，第二个%d才是我们期望的按照日期分隔日志。
				但是这样写完后，logback只认第一个%d, 所以实际的效果是按照月份对日志进行分隔。
修改第一个%d的写法为：%d{yyyy-MM,aux} 这样就可以按照日期分隔了 -->
            <fileNamePattern>${LOG_HOME}/%d{yyyy-MM,aux}/${FILE_NAME}-%d{yyyy-MM-dd}-%i.log</fileNamePattern>
            <maxFileSize>100MB</maxFileSize>
            <!--日志文件保留天数-->
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <!-- 此日志文件只记录debug级别的 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>debug</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <appender name="ASYNC_LOG_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志，默认值80，如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值256 -->
        <queueSize>256</queueSize>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref="FILE_NAME"/>
    </appender>

    <!-- ########### 这里也有坑：如果使用多环境配置springProfile就不会对日志进行分隔了。还没找到原因，暂时这样写 -->
    <logger name="com.alibaba.nacos" level="INFO" additivity="false"/>
    <!-- 日志输出级别 -->
    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="ASYNC_LOG_FILE"/>
    </root>
    
    <!-- 期望改成如下：支持多环境配置。这种写法存在的问题是：日志不会按照日期分隔了，还没找到解决办法 -->
    <!--    <springProfile name="dev,test">-->
<!--        <logger name="com.alibaba.nacos" level="INFO" additivity="false"/>-->
<!--        <logger name="api" level="INFO">-->
<!--            <appender-ref ref="ASYNC_API_FILE"/>-->
<!--        </logger>-->
<!--        <root level="INFO">-->
<!--            <appender-ref ref="CONSOLE"/>-->
<!--            <appender-ref ref="ASYNC_INFO_FILE"/>-->
<!--        </root>-->
<!--    </springProfile>-->

<!--    <springProfile name="testprerel,abroad,inn,innprerel,innrel,innusa,online,prenew,preusa,testrel,yace">-->
<!--        <logger name="com.alibaba.nacos" level="INFO" additivity="false"/>-->
<!--        <logger name="api" level="INFO" additivity="false">-->
<!--            <appender-ref ref="ASYNC_API_FILE"/>-->
<!--        </logger>-->
<!--        <root level="INFO">-->
<!--            <appender-ref ref="ASYNC_INFO_FILE"/>-->
<!--        </root>-->
<!--    </springProfile>-->
</configuration>
```

