

### 1、openFeign直连api，不经过nacos

```java
@FeignClient(value = "acc", url = "http://localhost:8092/acc")
public interface FeignAccountService {
    @PostMapping("/user/list")
    Result userList(@RequestBody UserListDTO userListDTO);
}
```

参考：[[FEIGN 直连API，FEIGN不使用EUREKA直接调用微服务](https://www.greenhtml.com/archives/feign-direct-api.html)](https://www.greenhtml.com/archives/feign-direct-api.html)

### 2、openFeign日志打印

feign提供了日志打印功能，可以通过配置来调整日志级别，从而了解Feign中HTTP请求的细节
日志级别有一下四个：
none：默认的，不显示任何日志
basic：仅记录请求方法，URL响应状态码，及执行时间
headers：除了basic中定义的信息之外还有请求和响应头信息
full：除了headers中定义的信息之外，还有请求和响应的正文及元数据
具体配置如下：
一、 新建配置类FeignConfig

```java
@Configuration
public class FeignConfig {
    @Bean
    Logger.Level feignLoggerLevel(){
        return Logger.Level.FULL;
    }
}
1234567
```

二、yml文件

```java
logging:
  level:
     #feogn日志以什么级别监视那个接口
     com.zhutianlu.springcloud.service.PaymentFeignService: debug
```

### 3 Feign Hystrix (HystrixCommonKey) 设置单独接口的超时时间和FallBack

如何配置好`Hystrix`和`Ribbon`的超时时间呢？
其实是有套路的。因为`Feign`的请求：其实是`Hystrix`+`Ribbon`。`Hystrix`在最外层，然后再到`Ribbon`，最后里面的是`http`请求。所以说。`Hystrix`的熔断时间必须大于`Ribbon`的 ( `ConnectTimeout` + `ReadTimeout` )。而如果`Ribbon`开启了重试机制，还需要乘以对应的重试次数，保证在`Ribbon`里的请求还没结束时，`Hystrix`的熔断时间不会超时。

**先说结论：HystrixCommonKey生成方法：类名#方法名(入参类型)**

```yaml
hystrix:
  threadpool:
    default:
      # 核心线程池大小  默认10
      coreSize: 20
      # 最大最大线程池大小
      maximumSize: 30
      # 此属性允许maximumSize的配置生效。 那么该值可以等于或高于coreSize。 设置coreSize <maximumSize会创建一个线程池，该线程池可以支持maximumSize并发，但在相对不活动期间将向系统返回线程。 （以keepAliveTimeInMinutes为准）
      allowMaximumSizeToDivergeFromCoreSize: true
      # 请求等待队列
      maxQueueSize: 10
      # 队列大小拒绝阀值 在还未超过请求等待队列时也会拒绝的大小
      queueSizeRejectionThreshold: 10
  command:
    LimitCheckApi#rcsLimitCheck(RpcRequest):  #default全局有效 默认值为 commonKey commonKey生成方法在 Feign.configKey(target.type(), method) 中
      fallback:
        enabled: true
      execution:
        timeout:
          #如果enabled设置为false，则请求超时交给ribbon控制,为true,则超时作为熔断根据
          enabled: true
        isolation:
          #隔离策略，有THREAD和SEMAPHORE
          #THREAD - 它在单独的线程上执行，并发请求受线程池中的线程数量的限制
          #SEMAPHORE - 它在调用线程上执行，并发请求受到信号量计数的限制
          #对比：https://www.cnblogs.com/java-synchronized/p/7927726.html
          thread:
            timeoutInMilliseconds: 800 #断路器超时时间，默认1000ms
    LimitCheckApi#testTimeOutFallBack(long):
      fallback:
        enabled: true
      execution:
        timeout:
            #如果enabled设置为false，则请求超时交给ribbon控制,为true,则超时作为熔断根据
            enabled: true
        isolation:
          #隔离策略，有THREAD和SEMAPHORE
          #THREAD - 它在单独的线程上执行，并发请求受线程池中的线程数量的限制
          #SEMAPHORE - 它在调用线程上执行，并发请求受到信号量计数的限制
          #对比：https://www.cnblogs.com/java-synchronized/p/7927726.html
          thread:
            timeoutInMilliseconds: 800 #断路器超时时间，默认1000ms
 
feign:
  hystrix:
    enabled: true
```

参考: 

[Hystrix针对某个方法单独设置超时时间](https://blog.csdn.net/jerry010101/article/details/90143919?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-2&spm=1001.2101.3001.4242)

[SpringCloud OpenFeign超时配置详解](https://blog.csdn.net/a1036645146/article/details/108297183)

### 4 mybatis-plus 自定义查询SQL

- 使用@select注解 + Wrapper 

```java
@Select("select * from `user` ${ew.customSqlSegment}")
List<User> selectAll(@Param(Constants.WRAPPER) Wrapper wrapper);
```

- 使用xml + Wrapper 

  ```java
  List<User> selectAll(@Param(Constants.WRAPPER) Wrapper wrapper);
  ```

  ```xml
  <select id="selectAll" resultType="com.zimug.example.model.User">
    select * from `user` ${ew.customSqlSegment}
  </select>
  ```

- 测试

  ```java
  @Test
  public void testCustomSQL2() {
    LambdaQueryWrapper<User> query = new LambdaQueryWrapper<>();
    query.eq(User::getName, "字母");
  
    List<User> list = userMapper.selectAll(query);
    list.forEach(System.out::println);
  }
  ```


### 5、arthas热部署

- 1 jad命令` 将需要更改的文件先进行反编译，保存下来 ，编译器修改。修改完以后需要将类重新加载到JVM

```java
$ jad --source-only com.example.demo.DemoApplication > /data/DemoApplication.java
```

- 2 `SC命令` “Search-Class” 的简写，查找当前类是哪个classLoader加载的

  ```bash
  [arthas@16340]$ sc -d *ApiInterceptor |grep classLoader
   classLoaderHash   18b4aac2		#类加载器  编号
  ```

- 3 MC (Memory Compiler/内存编译器)，编译`.java`文件生成`.class` 

  `MC命令` 用指定的classloader重新将类在内存中编译

  ```bash
  $ mc -c 18b4aac2 /data/DemoApplication.java -d /data 
  Memory compiler output:
  /data/com/example/demo/DemoApplication.class
  ```

- 4 redefine：加载外部的`.class`文件，redefine jvm已加载的类。

  ```bash
  $ redefine /data/com/example/demo/DemoApplication.class  
  redefine success, size: 1
  ```

  这样我们就用`arthas`现实了不停机、不发包替换了生产环境的Java代码

### 6.springboot打成jar包后无法解压

Springboot打出来的jar，用压缩工具解压报错。Why? 先说解决办法

#### 1、解决办法

> executable属性导致的，属性改成false后重新打包，就可以解压

```
<plugin>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-maven-plugin</artifactId>
    <configuration>
        <executable>true</executable>
    </configuration>
</plugin>
```

那么，executable设置成true作用是什么呢？为什么设置成true就无法解压呢？

#### 2、executable设置成true作用

一般情况下，我们运行jar的方式为：

> java -jar xxx.jar

但如果你想在unix/linux上，像执行某个sh/服务那样运行jar，就需要把你的app打包成executable的jar。

官方解释：

> In addition to running Spring Boot applications by using `java -jar`, it is also possible to make fully executable applications for Unix systems. A fully executable jar can be executed like any other executable binary or it can be [registered with `init.d` or `systemd`](https://docs.spring.io/spring-boot/docs/current/reference/html/deployment-install.html#deployment-service). This makes it very easy to install and manage Spring Boot applications in common production environments.

【A fully executable jar】就是通过前面提到的，打包时把executable设置为true。

#### 3、无法解压的原因分析

完全可执行 的 jar/war 在文件前面嵌入了个 额外的脚本，这就使得有些命令会执行失败，比如 jar -xf 等。

这就是为什么解压工具无法解压的原因。

所以，如果你的jar是通过【java -jar】执行、或 放在servlet容器中执行，那么建议将executable设置为false。

> Fully executable jars work by embedding an extra script at the front of the file. Currently, some tools do not accept this format, so you may not always be able to use this technique. For example, `jar -xf` may silently fail to extract a jar or war that has been made fully executable. It is recommended that you make your jar or war fully executable only if you intend to execute it directly, rather than running it with `java -jar` or deploying it to a servlet container.

#### 4、参考资料

https://docs.spring.io/spring-boot/docs/current/reference/html/deployment-install.html#deployment-service

### 7 logback 日志分隔

需求：异步输出日志，日志文件按照每天进行分隔。

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <contextName>logback</contextName>
    <!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义变量后，可以使“${}”来使用变量。 -->
    <property name="LOG_HOME" value="./logs" />
    <property name="FILE_NAME" value="api"/>

    <!--输出到控制台-->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息-->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>debug</level>
        </filter>
        <encoder>
            <Pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</Pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!--输出到文件-->
    <appender name="LOG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 正在记录的日志文件的路径及文件名 -->
        <file>${LOG_HOME}/${FILE_NAME}.log</file>
        <!--日志文件输出格式-->
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 日志记录器的滚动策略，按日期，按大小记录 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- 日志归档 -->
            <!-- #######################	重点这里有坑！！！ 用到了两次%d，第一个%d是为了获取[年月]，第二个%d才是我们期望的按照日期分隔日志。
				但是这样写完后，logback只认第一个%d, 所以实际的效果是按照月份对日志进行分隔。
修改第一个%d的写法为：%d{yyyy-MM,aux} 这样就可以按照日期分隔了 -->
            <fileNamePattern>${LOG_HOME}/%d{yyyy-MM,aux}/${FILE_NAME}-%d{yyyy-MM-dd}-%i.log</fileNamePattern>
            <maxFileSize>100MB</maxFileSize>
            <!--日志文件保留天数-->
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <!-- 此日志文件只记录debug级别的 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>debug</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <appender name="ASYNC_LOG_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志，默认值80，如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值256 -->
        <queueSize>256</queueSize>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref="FILE_NAME"/>
    </appender>

    <!-- ########### 这里也有坑：如果使用多环境配置springProfile就不会对日志进行分隔了。还没找到原因，暂时这样写 -->
    <logger name="com.alibaba.nacos" level="INFO" additivity="false"/>
    <!-- 日志输出级别 -->
    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="ASYNC_LOG_FILE"/>
    </root>
    
    <!-- 期望改成如下：支持多环境配置。这种写法存在的问题是：日志不会按照日期分隔了，还没找到解决办法 -->
    <!--    <springProfile name="dev,test">-->
<!--        <logger name="com.alibaba.nacos" level="INFO" additivity="false"/>-->
<!--        <logger name="api" level="INFO">-->
<!--            <appender-ref ref="ASYNC_API_FILE"/>-->
<!--        </logger>-->
<!--        <root level="INFO">-->
<!--            <appender-ref ref="CONSOLE"/>-->
<!--            <appender-ref ref="ASYNC_INFO_FILE"/>-->
<!--        </root>-->
<!--    </springProfile>-->

<!--    <springProfile name="testprerel,abroad,inn,innprerel,innrel,innusa,online,prenew,preusa,testrel,yace">-->
<!--        <logger name="com.alibaba.nacos" level="INFO" additivity="false"/>-->
<!--        <logger name="api" level="INFO" additivity="false">-->
<!--            <appender-ref ref="ASYNC_API_FILE"/>-->
<!--        </logger>-->
<!--        <root level="INFO">-->
<!--            <appender-ref ref="ASYNC_INFO_FILE"/>-->
<!--        </root>-->
<!--    </springProfile>-->
</configuration>
```

### 8 [linux内存不足导致java进程被kill掉](https://www.cnblogs.com/zjhgx/p/12112440.html)

记得之前在国内现金贷贷超放量时，后台java进程莫名奇妙就没了，

查看 /var/log/message 出现如下日志，标明，Linux 系统自身把 Java 进程杀掉了

```
Jun 28 02:58:27 hilife-dev001 kernel: Out of memory: Kill process 14561 (java) score 52 or sacrifice child
```

当 Linux 系统内存不足时，系统会把当前系统占用系统内存过高的进程当做流氓进程，然后系统发出信号将这个流氓进程杀掉，最后导致 Java 应用服务不能使用

解决方法
方法1：通过调整 JVM 参数限制最大可使用内存

-Xmx2g

方法2：启用 swap 分区
参考:https://help.aliyun.com/knowledge_detail/42534.html
方法3：增加物理内存或增加机器
方法4：将应用分配到压力较小的服务器上

#### 设置linux在内存不足的时候,不会自动杀进程

cat /proc/version，查看linux内核版本
如果linux内核版本<3.5，那么swapiness设置为0，这样系统宁愿swap也不会oom killer（杀掉进程）
如果linux内核版本>=3.5，那么swapiness设置为1，这样系统宁愿swap也不会oom killer
echo 0 > /proc/sys/vm/swappiness
echo vm.swapiness=0 >> /etc/sysctl.conf

### 9 查看CPU负载和利用率

https://mp.weixin.qq.com/s/M7Z6RSbMAZX1Lzl9sGWRxw

### **1.CPU负载和CPU利用率的区别是什么？**

首先，我们可以通过`uptime`，`w`或者`top`命令看到CPU的平均负载。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhvwRIlJd8pSfSb6AAxw1kUhFPJ8KibRia4KxkHWHwBQvTOkhtib39Kxfvg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhDY6yINBYhEycwlZWr8XxGqhiaS5mozVMVZ3yq42H2dAyZWgQXxkFUqg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



**Load Average** ：负载的3个数字，比如上图的4.86，5.28，5.00，分别代表系统在过去的1分钟，5分钟，15分钟内的系统平均负载。他代表的是**当前系统正在运行的和处于等待运行的进程数之和**。也指的是处于**可运行状态**和**不可中断状态**的平均进程数。

如果单核CPU的话，负载达到1就代表CPU已经达到满负荷的状态了，超过1，后面的进行就需要排队等待处理了。

如果是是多核多CPU的话，假设现在服务器是2个CPU，每个CPU2个核，那么总负载不超过4都没什么问题。

怎么查看CPU有多少核呢？

通过命令`cat /proc/cpuinfo | grep "model name"`查看CPU的情况。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhSuPhGGBMah9FW9Z6bI1lzsHwDCJiaepVIicic3JsD6GXl28ZBcJXR22Ag/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



通过`cat /proc/cpuinfo | grep "cpu cores"`查看CPU的核数

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhOemAFZSIiaase0bGTt4Mt8AXT4hJec9m26eQbvxrM6W1lI0QgPAglwA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



**CPU 利用率**：和负载不同，CPU利用率指的是当前**正在运行**的进程实时占用CPU的百分比，他是对一段时间内CPU使用状况的统计。

我举个栗子🌰：

假设你们公司厕所有1个坑位，有一个人占了坑位，这时候负载就是1，如果还有一个人在排队，那么负载就是2。

如果在1个小时内，A上厕所花了10分钟，B上厕所花了20分钟，剩下30分钟厕所都没人使用，那么这一个小时内利用率就是50%。

###  

### **2.那如果CPU负载很高，利用率却很低该怎么办？**

CPU负载很高，利用率却很低，说明处于等待状态的任务很多，负载越高，代表可能很多僵死的进程。通常这种情况是IO密集型的任务，大量请求在请求相同的IO，导致任务队列堆积。

同样，可以先通过`top`命令观察(截图只是示意，不代表真实情况)，假设发现现在确实是高负载低使用率。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhZtqWKVS8iad2rYo1Yj3BZ1pksWpkgdpicYms24qDnBLXFzJeOPFRJiciag/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



然后，再通过命令`ps -axjf`查看是否存在状态为`D+`状态的进程，这个状态指的就是不可中断的睡眠状态的进程。处于这个状态的进程无法终止，也无法自行退出，只能通过恢复其依赖的资源或者重启系统来解决。(对不起，我截不到D+的状态)

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhIM5P9GSeFqQ3cIgDiaNNPMpbMU5wJXZBw4fiaaT7CGSpDK1ntx9OUXfg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



###  

### **3.那如果负载很低，利用率却很高呢？**

如果你的公司只有一个厕所，外面没人排队，却有一个人在里面上了大半个小时，这说明什么？

两种可能：他没带纸，或者一些奇怪的事情发生了？

这表示CPU的任务并不多，但是任务执行的时间很长，大概率就是你写的代码本身有问题，通常是计算密集型任务，生成了大量耗时短的计算任务。

怎么排查？直接`top`命令找到使用率最高的任务，定位到去看看就行了。如果代码没有问题，那么过段时间CPU使用率就会下降的。

###  

### **4.那如果CPU使用率达到100%呢？怎么排查？**

1. 通过`top`找到占用率高的进程。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhuRsibVXxW9SRfyqpQ3BibwBQPtgsCBfDAaeXdYcVeQTUjuYYIocdqMeA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



1. 通过`top -Hp pid`找到占用CPU高的线程ID。这里找到958的线程ID

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhRs9ZKX1UAuuABVHeqWiaMJsDOUjGIjUyHnJAbLEicWgD4iaWQYaibklbag/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



1. 再把线程ID转化为16进制，`printf "0x%x\n" 958`，得到线程ID`0x3be`

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhKOCk3psjNH4lOMxJwKmP5033B8icpshzkQvdzDottaVh28kcZ6zJlxw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



1. 通过命令`jstack 163 | grep '0x3be' -C5 --color` 或者 `jstack 163|vim +/0x3be -` 找到有问题的代码

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUmvPFvQ3yVL1tQYGibHicYClhgPK9rmZ5npLAtgmIia4TLjFdGVrSXAAZeMn3m5RE8tKMLn9WBnU9CZw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 5 变量目录查找内容

```shell

dir=/data/service/cloud-account/logs/2021-07
 
for file in $dir/*; do
    echo $file
    match=$(echo $file | grep "log.gz")
    if [ "$match" != "" ]
    then
        echo "$file 是压缩文件"
    else
        echo "$file 不是压缩文件"
    fi
done


#!/bin/bash

dir=/data/service/cloud-account/logs/2021-07
cd $dir

#for file in $dir/*; do
for file in $(find  .  -name "api-*"  |  sort)
do
   # echo $file
    match=$(echo $file | grep "log.gz")
    if [ "$match" != "" ]
    then
        #echo "$file 是压缩文件"
        echo $file
        gzip -dc $file | grep 'acc/v1/init' | grep 'osType=05' -c
    else
        #echo "$file 不是压缩文件"
        echo $file
        grep 'acc/v1/init' $file | grep 'osType=05' -c
    fi
done
```



